{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDI Capstone Project, Part 0: Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from external_variables import data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(path_to_file,destination,new_name):\n",
    "    \"\"\"Function for unzipping a zip file. \n",
    "    \n",
    "    PARAMETERS:\n",
    "    **********\n",
    "\n",
    "    INPUTS: \n",
    "    path_to_file = file_path/file_name to zip file. \n",
    "    destionation = destination directory for zip file's contents. \n",
    "\n",
    "    OUTPUTS: \n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    files_in_dir_before = os.listdir(destination)\n",
    "    zip_ref = zipfile.ZipFile(path_to_file, 'r')\n",
    "    zip_ref.extractall(destination)\n",
    "    zip_ref.close()\n",
    "    files_in_dir_after = os.listdir(destination)\n",
    "    \n",
    "    unzipped_dir = [di for di in files_in_dir_after if di not in files_in_dir_before]\n",
    "    #if len(unzipped_dir)==1: \n",
    "    #    os.rename(os.path.join(destination,unzipped_dir[0]),os.path.join(destination,new_name))\n",
    "        \n",
    "    return\n",
    "\n",
    "def make_directory(dir_path): \n",
    "    try: \n",
    "        os.mkdir(dir_path)\n",
    "    except FileExistsError: \n",
    "        print('directory already exists: '+dir_path)\n",
    "    return None\n",
    "\n",
    "def download_file_http(url,final_dest,final_name):  \n",
    "    r = requests.get(url)\n",
    "    with open(os.path.join(final_dest,final_name), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return final_dest,final_name\n",
    "\n",
    "def download_file_ftp(url,final_dest,final_name):\n",
    "    urllib.request.urlretrieve(url, os.path.join(final_dest,final_name))\n",
    "    return final_dest,final_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ICIS-Air data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists: ./data/ICIS-Air\n"
     ]
    }
   ],
   "source": [
    "icis_path = os.path.join(data_path,'ICIS-Air')\n",
    "make_directory(icis_path)\n",
    "\n",
    "url = 'https://echo.epa.gov/files/echodownloads/ICIS-AIR_downloads.zip'\n",
    "file_path,file_name = download_file_http(url,icis_path,'ICIS-Air.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'ICIS-Air')\n",
    "os.remove(os.path.join(file_path,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test to check filenames. \n",
    "def TEST_ICISAir_filenames(icis_path): \n",
    "    \n",
    "    correct_fnames = ['ICIS-AIR_FACILITIES.csv','ICIS-AIR_PROGRAMS.csv',\n",
    "                      'ICIS-AIR_FCES_PCES.csv','ICIS-AIR_PROGRAM_SUBPARTS.csv',\n",
    "                      'ICIS-AIR_FORMAL_ACTIONS.csv','ICIS-AIR_STACK_TESTS.csv',\n",
    "                      'ICIS-AIR_INFORMAL_ACTIONS.csv','ICIS-AIR_TITLEV_CERTS.csv',\n",
    "                      'ICIS-AIR_POLLUTANTS.csv','ICIS-AIR_VIOLATION_HISTORY.csv']\n",
    "    real_fnames = os.listdir(icis_path)\n",
    "    missing_files = [fname for fname in correct_fnames if fname not in real_fnames]\n",
    "    \n",
    "    message = \"The following ICIS-Air files are missing: \"+\", \".join(missing_files)\n",
    "    assert not missing_files, message\n",
    "\n",
    "TEST_ICISAir_filenames(icis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_ICISAir_columns(): \n",
    "    \n",
    "    # ICIS-AIR_FCES_PCES.csv\n",
    "    correct_columns = ['PGM_SYS_ID', 'ACTIVITY_ID', 'STATE_EPA_FLAG', \n",
    "                       'ACTIVITY_TYPE_CODE', 'ACTIVITY_TYPE_DESC', \n",
    "                       'COMP_MONITOR_TYPE_CODE', 'COMP_MONITOR_TYPE_DESC', \n",
    "                       'ACTUAL_END_DATE', 'PROGRAM_CODES'] \n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'ICIS-Air','ICIS-AIR_FCES_PCES.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in ICIS-AIR_FCES_PCES.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "    \n",
    "    # ICIS-AIR_VIOLATION_HISTORY.csv\n",
    "    correct_columns = ['PGM_SYS_ID', 'ACTIVITY_ID', 'AGENCY_TYPE_DESC', 'STATE_CODE',\n",
    "                       'AIR_LCON_CODE', 'COMP_DETERMINATION_UID', 'ENF_RESPONSE_POLICY_CODE',\n",
    "                       'PROGRAM_CODES', 'PROGRAM_DESCS', 'POLLUTANT_CODES', 'POLLUTANT_DESCS',\n",
    "                       'EARLIEST_FRV_DETERM_DATE', 'HPV_DAYZERO_DATE', 'HPV_RESOLVED_DATE']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'ICIS-Air','ICIS-AIR_VIOLATION_HISTORY.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in ICIS-AIR_VIOLATION_HISTORY.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "    \n",
    "    # ICIS-AIR_FACILITIES.csv\n",
    "    correct_columns = ['PGM_SYS_ID', 'REGISTRY_ID', 'FACILITY_NAME', 'STREET_ADDRESS', 'CITY',\n",
    "                       'COUNTY_NAME', 'STATE', 'ZIP_CODE', 'EPA_REGION', 'SIC_CODES',\n",
    "                       'NAICS_CODES', 'FACILITY_TYPE_CODE', 'AIR_POLLUTANT_CLASS_CODE',\n",
    "                       'AIR_POLLUTANT_CLASS_DESC', 'AIR_OPERATING_STATUS_CODE',\n",
    "                       'AIR_OPERATING_STATUS_DESC', 'CURRENT_HPV', 'LOCAL_CONTROL_REGION_CODE',\n",
    "                       'LOCAL_CONTROL_REGION_NAME']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'ICIS-Air','ICIS-AIR_FACILITIES.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in ICIS-AIR_FACILITIES.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "    \n",
    "TEST_ICISAir_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICIS-AIR_FCES_PCES.csv\n",
    "ICIS-AIR_VIOLATION_HISTORY.csv\n",
    "ICIS-AIR_FACILITIES.csv\n",
    "\n",
    "FRS_PROGRAM_LINKS.csv\n",
    "\n",
    "2014v2facilities.csv\n",
    "2011neiv2_facility.csv\n",
    "2008neiv3_facility.csv\n",
    "\n",
    "ECHO_EXPORTER.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ECHO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_path = os.path.join(data_path,'ECHO')\n",
    "make_directory(echo_path)\n",
    "\n",
    "url = 'https://echo.epa.gov/files/echodownloads/echo_exporter.zip'\n",
    "file_path,file_name = download_file_http(url,echo_path,'ECHO.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'ECHO')\n",
    "os.remove(os.path.join(file_path,file_name))\n",
    "\n",
    "url = 'https://echo.epa.gov/system/files/echo_exporter_columns_02282019.xlsx'\n",
    "file_path,file_name = download_file_http(url,echo_path,'echo_exporter_columns_02282019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_ECHO_filenames(echo_path): \n",
    "    \n",
    "    correct_fnames = ['echo_exporter_columns_02282019.xlsx', 'ECHO_EXPORTER.csv']\n",
    "    real_fnames = os.listdir(echo_path)\n",
    "    missing_files = [fname for fname in correct_fnames if fname not in real_fnames]\n",
    "    \n",
    "    message = \"The following ECHO files are missing: \"+\", \".join(missing_files)\n",
    "    assert not missing_files, message\n",
    "    \n",
    "TEST_ECHO_filenames(echo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_ECHO_columns(): \n",
    "    \n",
    "    # ECHO_EXPORTER.csv\n",
    "    correct_columns = ['REGISTRY_ID','FAC_NAME','FAC_STREET','FAC_CITY','FAC_STATE',\n",
    "                       'FAC_ZIP','FAC_COUNTY','FAC_FIPS_CODE','FAC_EPA_REGION',\n",
    "                       'FAC_INDIAN_CNTRY_FLG','FAC_FEDERAL_FLG','FAC_US_MEX_BORDER_FLG',\n",
    "                       'FAC_CHESAPEAKE_BAY_FLG','FAC_NAA_FLAG','FAC_LAT','FAC_LONG',\n",
    "                       'FAC_MAP_ICON','FAC_COLLECTION_METHOD','FAC_REFERENCE_POINT',\n",
    "                       'FAC_ACCURACY_METERS','FAC_DERIVED_TRIBES','FAC_DERIVED_HUC',\n",
    "                       'FAC_DERIVED_WBD','FAC_DERIVED_STCTY_FIPS','FAC_DERIVED_ZIP',\n",
    "                       'FAC_DERIVED_CD113','FAC_DERIVED_CB2010','FAC_PERCENT_MINORITY',\n",
    "                       'FAC_POP_DEN','FAC_MAJOR_FLAG','FAC_ACTIVE_FLAG','FAC_MYRTK_UNIVERSE',\n",
    "                       'FAC_INSPECTION_COUNT','FAC_DATE_LAST_INSPECTION',\n",
    "                       'FAC_DAYS_LAST_INSPECTION','FAC_INFORMAL_COUNT',\n",
    "                       'FAC_DATE_LAST_INFORMAL_ACTION','FAC_FORMAL_ACTION_COUNT',\n",
    "                       'FAC_DATE_LAST_FORMAL_ACTION','FAC_TOTAL_PENALTIES',\n",
    "                       'FAC_PENALTY_COUNT','FAC_DATE_LAST_PENALTY','FAC_LAST_PENALTY_AMT',\n",
    "                       'FAC_QTRS_WITH_NC','FAC_PROGRAMS_WITH_SNC','FAC_COMPLIANCE_STATUS',\n",
    "                       'FAC_SNC_FLG','FAC_3YR_COMPLIANCE_HISTORY','AIR_FLAG','NPDES_FLAG',\n",
    "                       'SDWIS_FLAG','RCRA_FLAG','TRI_FLAG','GHG_FLAG','AIR_IDS',\n",
    "                       'CAA_PERMIT_TYPES','CAA_NAICS','CAA_SICS','CAA_EVALUATION_COUNT',\n",
    "                       'CAA_DAYS_LAST_EVALUATION','CAA_INFORMAL_COUNT',\n",
    "                       'CAA_FORMAL_ACTION_COUNT','CAA_DATE_LAST_FORMAL_ACTION',\n",
    "                       'CAA_PENALTIES','CAA_LAST_PENALTY_DATE','CAA_LAST_PENALTY_AMT',\n",
    "                       'CAA_QTRS_WITH_NC','CAA_COMPLIANCE_STATUS','CAA_HPV_FLAG',\n",
    "                       'CAA_3YR_COMPL_QTRS_HISTORY','NPDES_IDS','CWA_PERMIT_TYPES',\n",
    "                       'CWA_COMPLIANCE_TRACKING','CWA_NAICS','CWA_SICS',\n",
    "                       'CWA_INSPECTION_COUNT','CWA_DAYS_LAST_INSPECTION',\n",
    "                       'CWA_INFORMAL_COUNT','CWA_FORMAL_ACTION_COUNT',\n",
    "                       'CWA_DATE_LAST_FORMAL_ACTION','CWA_PENALTIES',\n",
    "                       'CWA_LAST_PENALTY_DATE','CWA_LAST_PENALTY_AMT','CWA_QTRS_WITH_NC',\n",
    "                       'CWA_COMPLIANCE_STATUS','CWA_SNC_FLAG','CWA_13QTRS_COMPL_HISTORY',\n",
    "                       'CWA_13QTRS_EFFLNT_EXCEEDANCES','CWA_3_YR_QNCR_CODES','RCRA_IDS',\n",
    "                       'RCRA_PERMIT_TYPES','RCRA_NAICS','RCRA_INSPECTION_COUNT',\n",
    "                       'RCRA_DAYS_LAST_EVALUATION','RCRA_INFORMAL_COUNT',\n",
    "                       'RCRA_FORMAL_ACTION_COUNT','RCRA_DATE_LAST_FORMAL_ACTION',\n",
    "                       'RCRA_PENALTIES','RCRA_LAST_PENALTY_DATE','RCRA_LAST_PENALTY_AMT',\n",
    "                       'RCRA_QTRS_WITH_NC','RCRA_COMPLIANCE_STATUS','RCRA_SNC_FLAG',\n",
    "                       'RCRA_3YR_COMPL_QTRS_HISTORY','SDWA_IDS','SDWA_SYSTEM_TYPES',\n",
    "                       'SDWA_INFORMAL_COUNT','SDWA_FORMAL_ACTION_COUNT','SDWA_COMPLIANCE_STATUS',\n",
    "                       'SDWA_SNC_FLAG','TRI_IDS','TRI_RELEASES_TRANSFERS',\n",
    "                       'TRI_ON_SITE_RELEASES','TRI_OFF_SITE_TRANSFERS','TRI_REPORTER_IN_PAST',\n",
    "                       'FEC_CASE_IDS','FEC_NUMBER_OF_CASES','FEC_LAST_CASE_DATE',\n",
    "                       'FEC_TOTAL_PENALTIES','GHG_IDS','GHG_CO2_RELEASES','DFR_URL',\n",
    "                       'FAC_SIC_CODES','FAC_NAICS_CODES','FAC_DATE_LAST_INSPECTION_EPA',\n",
    "                       'FAC_DATE_LAST_INSPECTION_STATE','FAC_DATE_LAST_FORMAL_ACT_EPA',\n",
    "                       'FAC_DATE_LAST_FORMAL_ACT_ST','FAC_DATE_LAST_INFORMAL_ACT_EPA',\n",
    "                       'FAC_DATE_LAST_INFORMAL_ACT_ST','FAC_FEDERAL_AGENCY','TRI_REPORTER',\n",
    "                       'FAC_IMP_WATER_FLG','EJSCREEN_FLAG_US']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'ECHO','ECHO_EXPORTER.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in ECHO_EXPORTER.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "\n",
    "TEST_ECHO_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download FRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frs_path = os.path.join(data_path,'FRS')\n",
    "make_directory(frs_path)\n",
    "\n",
    "url = 'https://echo.epa.gov/files/echodownloads/frs_downloads.zip'\n",
    "file_path,file_name = download_file_http(url,frs_path,'FRS.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'FRS')\n",
    "os.remove(os.path.join(file_path,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_FRS_filenames(frs_path): \n",
    "    \n",
    "    correct_fnames = ['FRS_NAICS_CODES.csv','FRS_FACILITIES.csv',\n",
    "                      'FRS_SIC_CODES.csv','FRS_PROGRAM_LINKS.csv']\n",
    "    real_fnames = os.listdir(frs_path)\n",
    "    missing_files = [fname for fname in correct_fnames if fname not in real_fnames]\n",
    "    \n",
    "    message = \"The following FRS files are missing: \"+\", \".join(missing_files)\n",
    "    assert not missing_files, message\n",
    "\n",
    "TEST_FRS_filenames(frs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_FRS_columns(): \n",
    "    \n",
    "    # FRS_PROGRAM_LINKS.csv\n",
    "    correct_columns = ['PGM_SYS_ACRNM', 'PGM_SYS_ID', 'REGISTRY_ID', \n",
    "                       'PRIMARY_NAME', 'LOCATION_ADDRESS', 'SUPPLEMENTAL_LOCATION', \n",
    "                       'CITY_NAME', 'COUNTY_NAME','FIPS_CODE', 'STATE_CODE', \n",
    "                       'STATE_NAME', 'COUNTRY_NAME', 'POSTAL_CODE']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'FRS','FRS_PROGRAM_LINKS.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in FRS_PROGRAM_LINKS.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "\n",
    "TEST_FRS_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NEI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists: ./data/NEI\n"
     ]
    }
   ],
   "source": [
    "nei_path = os.path.join(data_path,'NEI')\n",
    "make_directory(nei_path)\n",
    "\n",
    "# For 2008\n",
    "url = 'ftp://newftp.epa.gov/air/nei/2008/data_summaries/2008neiv3_facility.zip'\n",
    "file_path,file_name = download_file_ftp(url,nei_path,'NEI.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'NEI')\n",
    "os.remove(os.path.join(file_path,file_name))\n",
    "os.rename(os.path.join(file_path,'2008neiv3_facility','2008neiv3_facility.csv'),\n",
    "          os.path.join(file_path,'2008neiv3_facility.csv'))\n",
    "os.remove(os.path.join(file_path,'2008neiv3_facility'))\n",
    "\n",
    "# For 2011\n",
    "url = 'ftp://newftp.epa.gov/air/nei/2011/data_summaries/2011v2/2011neiv2_facility.zip'\n",
    "file_path,file_name = download_file_ftp(url,nei_path,'NEI.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'NEI')\n",
    "os.remove(os.path.join(file_path,file_name))\n",
    "\n",
    "# For 2014\n",
    "url = 'ftp://newftp.epa.gov/air/nei/2014/data_summaries/2014v2/2014neiv2_facility.zip'\n",
    "file_path,file_name = download_file_ftp(url,nei_path,'NEI.zip')\n",
    "unzip_file(os.path.join(file_path,file_name),file_path,'NEI')\n",
    "os.remove(os.path.join(file_path,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_NEI_filenames(nei_path): \n",
    "    \n",
    "    correct_fnames = ['2014v2facilities.csv', '2011neiv2_facility.csv', \n",
    "                      '2008neiv3_facility.csv']\n",
    "    real_fnames = os.listdir(nei_path)\n",
    "    missing_files = [fname for fname in correct_fnames if fname not in real_fnames]\n",
    "    \n",
    "    message = \"The following NEI files are missing: \"+\", \".join(missing_files)\n",
    "    assert not missing_files, message\n",
    "    \n",
    "TEST_NEI_filenames(nei_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_NEI_columns(): \n",
    "    \n",
    "    # 2014v2facilities.csv\n",
    "    correct_columns = ['eis_facility_site_id', 'program_system_code', \n",
    "                       'alt_agency_id', 'region_cd', 'st_usps_cd', \n",
    "                       'county_name', 'state_and_county_fips_code', \n",
    "                       'tribal_name', 'facility_site_name', 'naics_cd', \n",
    "                       'naics_description', 'facility_source_type', \n",
    "                       'latitude_msr', 'longitude_msr', 'location_address_text', \n",
    "                       'locality', 'addr_state_cd', 'address_postal_code', \n",
    "                       'emissions_operating_type', 'pollutant_cd', 'pollutant_desc', \n",
    "                       'total_emissions', 'uom', 'fips_state_code', 'company_name', \n",
    "                       'reporting_period']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'NEI','2014v2facilities.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in 2014v2facilities.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "    \n",
    "    # 2011neiv2_facility.csv\n",
    "    correct_columns = ['eis_facility_site_id', 'program_system_cd', \n",
    "                       'alt_agency_id', 'region_cd', 'st_usps_cd', 'county_name', \n",
    "                       'state_and_county_fips_code', 'tribal_name', \n",
    "                       'facility_site_name', 'naics_cd', 'facility_source_description', \n",
    "                       'facility_site_status_cd', 'latitude_msr', 'longitude_msr', \n",
    "                       'location_address_text', 'locality', 'addr_state_cd', \n",
    "                       'address_postal_code', 'emissions_op_type_code', 'pollutant_cd', \n",
    "                       'description', 'total_emissions', 'uom']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'NEI','2011neiv2_facility.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in 2011neiv2_facility.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "    \n",
    "    # 2008neiv3_facility.csv\n",
    "    correct_columns = ['eis_facility_site_id', 'program_system_cd', 'alt_agency_id', \n",
    "                       'region_cd', 'st_usps_cd', 'county_name', \n",
    "                       'state_and_county_fips_code', 'tribal_name', 'facility_site_name', \n",
    "                       'naics_cd', 'facility_source_description', 'facility_site_status_cd', \n",
    "                       'latitude_msr', 'longitude_msr', 'location_address_text', 'locality', \n",
    "                       'addr_state_cd', 'address_postal_code', 'emissions_op_type_code', \n",
    "                       'pollutant_cd', 'description', 'total_emissions', 'uom']\n",
    "\n",
    "    first_ten = pd.read_csv(os.path.join(data_path,'NEI','2008neiv3_facility.csv'),nrows=10)\n",
    "    missing_columns = [col for col in correct_columns if col not in first_ten.columns]\n",
    "\n",
    "    message = \"The following columns are missing in 2008neiv3_facility.csv: \"+\\\n",
    "                                                            ', '.join(missing_columns)\n",
    "    assert not missing_columns, message\n",
    "\n",
    "TEST_NEI_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
