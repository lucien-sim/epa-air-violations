{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDI Capstone Project, Part 1: Linking inspections to violations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, no ID is given to unequivocally link violations to the inspections in which they were discovered. Therefore, a violation is linked ot an inspection (a \"failed\" inspection) if the inspection and violation occur at the same pollution source, if the violation occurs within `insp_viol_thresh_days` days of the previous inspection at the source, and if no other violations were reported between the inspection and violation of concern. `insp_viol_thresh_days` can be given any value. I chose 365 days because it gave the best model results. The purpose of the code in this notebook is to draw these connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from external_variables import data_path\n",
    "start_date = pd.Timestamp(year=2003,month=1,day=1)\n",
    "end_date = pd.Timestamp(year=2018,month=12,day=31)\n",
    "insp_viol_thresh_days = 365\n",
    "insp_event_thresh = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_inspections(file_path,start_date=pd.Timestamp(year=2013,month=1,day=1),\n",
    "                     end_date=pd.Timestamp(year=2018,month=12,day=31)):\n",
    "    \"\"\"Loads raw inspection data (directly from downloaded file), returns cleaned/parsed dataframe.\"\"\"\n",
    "    \n",
    "    # Load data, parse dates manually (didn't work in load function for some reason?)\n",
    "    fces_pces = pd.read_csv(file_path,dtype=str,parse_dates=['ACTUAL_END_DATE'])\n",
    "    fces_pces['ACTUAL_END_DATE'] = fces_pces['ACTUAL_END_DATE'].apply(\n",
    "                            lambda x: datetime.datetime.strptime(x,'%m-%d-%Y'))\n",
    "    \n",
    "    # Restrict dates to specified time period\n",
    "    fces_pces = fces_pces[(fces_pces['ACTUAL_END_DATE']>=start_date) & \n",
    "                          (fces_pces['ACTUAL_END_DATE']<=end_date)]\n",
    "    \n",
    "    # Drop inspections without a date, sort. \n",
    "    fces_pces = fces_pces.dropna(axis=0,subset=['ACTUAL_END_DATE'])\n",
    "    fces_pces = fces_pces.sort_values(by=['PGM_SYS_ID','ACTUAL_END_DATE'],axis=0)\n",
    "    \n",
    "    return fces_pces\n",
    "\n",
    "\n",
    "def time_since_prev(df,date_col='ACTUAL_END_DATE',group_col='PGM_SYS_ID'): \n",
    "    \"\"\"Adds new column: time since the previous inspection\"\"\"\n",
    "    if group_col is not None: \n",
    "        time_diff = df.groupby(group_col)[date_col].diff()/pd.Timedelta('1 days')\n",
    "        time_diff[time_diff.isnull()]=np.NaN\n",
    "        time_diff = time_diff.astype(float)\n",
    "    else: \n",
    "        time_diff = df[date_col].diff()/pd.Timedelta('1 days')\n",
    "        time_diff[time_diff.isnull()]=np.NaN\n",
    "        time_diff = time_diff.astype(float)\n",
    "    return time_diff\n",
    "\n",
    "\n",
    "def merge_events(df,time_since_col='time_since_prev',days_thresh=14): \n",
    "    \"\"\"Merge inspection events that occur within 14 days of each other\"\"\"\n",
    "    return df[((df[time_since_col]>days_thresh)) | (df[time_since_col].isna())]\n",
    "\n",
    "\n",
    "def load_violations(file_path,start_date=pd.Timestamp(year=2003,month=1,day=1),\n",
    "                     end_date=pd.Timestamp(year=2018,month=12,day=31)):\n",
    "    \"\"\"Loads inspection data directly from downloaded files, returns parsed and cleaned dataframe\"\"\"\n",
    "    \n",
    "    # Read in data\n",
    "    violations = pd.read_csv(file_path,dtype='str')\n",
    "    \n",
    "    viol_dates = violations['EARLIEST_FRV_DETERM_DATE'].copy()\n",
    "    viol_dates[violations['EARLIEST_FRV_DETERM_DATE'].isna()] = violations['HPV_DAYZERO_DATE'][\n",
    "                                                            violations['EARLIEST_FRV_DETERM_DATE'].isna()]\n",
    "    violations['VIOL_DATE'] = viol_dates\n",
    "    violations = violations.dropna(axis=0,subset=['VIOL_DATE'])\n",
    "    violations['VIOL_DATE'] = violations['VIOL_DATE'].apply(lambda x: \n",
    "                                                            datetime.datetime.strptime(x,'%m-%d-%Y'))\n",
    "    \n",
    "    # Restrict dates\n",
    "    violations = violations[(violations['VIOL_DATE']>=start_date) & \n",
    "                            (violations['VIOL_DATE']<=end_date)]\n",
    "    \n",
    "    # Sort by SOURCE ID and date. \n",
    "    violations = violations.sort_values(by=['PGM_SYS_ID','VIOL_DATE'],axis=0)\n",
    "    \n",
    "    return violations\n",
    "\n",
    "\n",
    "def link_viol_insp(inspections,violations,past_thresh=0,future_thresh=90):\n",
    "    \n",
    "    # Dictionary of violations--for easy access later. \n",
    "    viol_dict = {}\n",
    "    for source_id,source_data in violations[['PGM_SYS_ID','VIOL_DATE','ACTIVITY_ID'\n",
    "                                            ]].groupby('PGM_SYS_ID')[['ACTIVITY_ID','VIOL_DATE']]: \n",
    "        viol_dict[source_id] = source_data\n",
    "    \n",
    "    # Loop through all sources--link violations at that source to inspections. \n",
    "    pgmsysid,inspdate,violtf,actid = [],[],[],[]\n",
    "    insp_dates_by_source = inspections[['PGM_SYS_ID','ACTUAL_END_DATE']].groupby('PGM_SYS_ID')['ACTUAL_END_DATE']\n",
    "    for source_id,insp_dates in insp_dates_by_source:\n",
    "\n",
    "        # Initialize lists/arrays to store for each inspection: \n",
    "        insp_dates = np.asarray(insp_dates) # inspection dates\n",
    "        viol_tf = np.zeros(np.shape(insp_dates)) # inspection pass/fail\n",
    "        act_ids = [np.NaN]*len(insp_dates) # violation activity ids (when applicable)\n",
    "        viol_data = viol_dict.get(source_id)\n",
    "\n",
    "        # If there has been a violation at the source, mark corresponding inspections as failed and \n",
    "        # record violation activity ID for the violation associated with the inspection. \n",
    "        if viol_data is not None: \n",
    "            viol_dates = list(viol_data['VIOL_DATE'])\n",
    "            viol_actids = list(viol_data['ACTIVITY_ID'])\n",
    "            for viol_date,viol_actid in zip(viol_dates,viol_actids): \n",
    "                time_diffs = (viol_date-insp_dates)/datetime.timedelta(days=1)\n",
    "                time_diffs[(time_diffs<past_thresh) | (time_diffs>future_thresh)] = np.NaN\n",
    "                try: \n",
    "                    ind_viol = np.nanargmin(time_diffs)\n",
    "                    if viol_tf[ind_viol]==0:\n",
    "                        viol_tf[ind_viol] = 1\n",
    "                        act_ids[ind_viol] = str(viol_actid)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        # Accumulate inspection results in long vectors. \n",
    "        pgmsysid.extend([source_id]*len(insp_dates))\n",
    "        inspdate.extend(list(insp_dates))\n",
    "        violtf.extend(list(viol_tf))\n",
    "        actid.extend(list(act_ids))\n",
    "\n",
    "    # Create dataframe with inspection results. Add results to inspections dataframe with merge. \n",
    "    for_join = pd.DataFrame({\n",
    "        'PGM_SYS_ID':pgmsysid,\n",
    "        'ACTUAL_END_DATE':inspdate,\n",
    "        'VIOL':violtf,\n",
    "        'VIOL_ACTID':actid\n",
    "    })\n",
    "    for_join['DATE_JOIN'] = for_join['ACTUAL_END_DATE'].apply(str)\n",
    "    for_join = for_join.drop('ACTUAL_END_DATE',axis=1)\n",
    "    inspections['DATE_JOIN'] = inspections['ACTUAL_END_DATE'].apply(str)\n",
    "    new_df = pd.merge(inspections, for_join,  how='left', on=['PGM_SYS_ID','DATE_JOIN']).drop('DATE_JOIN',\n",
    "                                                                                              axis=1)  \n",
    "    # Adjust datatypes of new columns\n",
    "    new_df['VIOL'] = new_df['VIOL'].astype(dtype=int)\n",
    "    new_df['VIOL_ACTID'] = new_df['VIOL_ACTID'].astype(dtype=str)\n",
    "    \n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load inspection data\n",
    "\n",
    "**Source:** ICIS-AIR inspections database ([download summary](https://echo.epa.gov/tools/data-downloads/icis-air-download-summary)).\n",
    "\n",
    "**Known problems:** Texas, Louisiana, Nebraska, North Dakota might only have data after Oct 17, 2014. All other states should have data that's complete, back to to ~2003. Source: [known problems](https://echo.epa.gov/resources/echo-data/known-data-problems#alerts). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections_path = os.path.join(data_path,'ICIS-AIR_downloads','ICIS-AIR_FCES_PCES.csv')\n",
    "inspections = load_raw_inspections(inspections_path,start_date=start_date,end_date=end_date)\n",
    "\n",
    "#a = inspections.groupby(inspections['ACTUAL_END_DATE'].dt.year).count()\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111)\n",
    "#a[['PGM_SYS_ID']].plot(ax=ax)\n",
    "#ax.set_xlabel('Year')\n",
    "#ax.set_ylabel('Number of inspections, nationwide')\n",
    "#ax.set_ylim([0,85000])\n",
    "#fig.savefig('./figs/num_inspections_by_year.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean inspection data\n",
    "**Biggest problem:** Often, several inspections are reported at a single source on a single day, or over the course of a few days. I assume these are duplicates or are strongly associated with each other (i.e. are part of the same \"inspection event\"). I therefore decided to delete any inspections for which another inspection occurred at the same source within the previous `insp_event_thresh` days. I chose to set `insp_event_thresh` to 14 days. \n",
    "\n",
    "Days between consecutive inspection events, before cleaning: \n",
    "![time_btwn_insp](figs/time_between_insp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGM_SYS_ID</th>\n",
       "      <th>ACTIVITY_ID</th>\n",
       "      <th>STATE_EPA_FLAG</th>\n",
       "      <th>ACTIVITY_TYPE_CODE</th>\n",
       "      <th>ACTIVITY_TYPE_DESC</th>\n",
       "      <th>COMP_MONITOR_TYPE_CODE</th>\n",
       "      <th>COMP_MONITOR_TYPE_DESC</th>\n",
       "      <th>ACTUAL_END_DATE</th>\n",
       "      <th>PROGRAM_CODES</th>\n",
       "      <th>time_since_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>010000000901110001</td>\n",
       "      <td>3601073581</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PFF</td>\n",
       "      <td>PCE Off-Site</td>\n",
       "      <td>2017-01-20 00:00:00</td>\n",
       "      <td>CAANSPS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453768</th>\n",
       "      <td>010000000901110001</td>\n",
       "      <td>3601047975</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PFF</td>\n",
       "      <td>PCE Off-Site</td>\n",
       "      <td>2017-03-10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>01000000E000000001</td>\n",
       "      <td>3601532874</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-05-30 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>01000000E000000003</td>\n",
       "      <td>3601532881</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-04-18 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>01000000E000000004</td>\n",
       "      <td>3601545556</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-05-01 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PGM_SYS_ID ACTIVITY_ID STATE_EPA_FLAG ACTIVITY_TYPE_CODE  \\\n",
       "370      010000000901110001  3601073581              E                INS   \n",
       "1453768  010000000901110001  3601047975              E                INS   \n",
       "373      01000000E000000001  3601532874              E                INS   \n",
       "375      01000000E000000003  3601532881              E                INS   \n",
       "376      01000000E000000004  3601545556              E                INS   \n",
       "\n",
       "            ACTIVITY_TYPE_DESC COMP_MONITOR_TYPE_CODE COMP_MONITOR_TYPE_DESC  \\\n",
       "370      Inspection/Evaluation                    PFF           PCE Off-Site   \n",
       "1453768  Inspection/Evaluation                    PFF           PCE Off-Site   \n",
       "373      Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "375      Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "376      Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "\n",
       "             ACTUAL_END_DATE PROGRAM_CODES  time_since_prev  \n",
       "370      2017-01-20 00:00:00       CAANSPS              NaN  \n",
       "1453768  2017-03-10 00:00:00           NaN             49.0  \n",
       "373      2018-05-30 00:00:00        CAASIP              NaN  \n",
       "375      2018-04-18 00:00:00        CAASIP              NaN  \n",
       "376      2018-05-01 00:00:00        CAASIP              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Days since previous inspection\n",
    "inspections['time_since_prev'] = time_since_prev(inspections,date_col='ACTUAL_END_DATE',\n",
    "                                                 group_col='PGM_SYS_ID')\n",
    "inspections = merge_events(inspections,time_since_col='time_since_prev',days_thresh=insp_event_thresh)\n",
    "inspections.head()\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = inspections['time_since_prev'].hist(bins=np.linspace(0,100,101))\n",
    "#ax.set_xlabel('Days since previous inspection at source')\n",
    "#ax.set_ylabel('Frequency')\n",
    "#ax.set_title('Times between inspections at sources, 2003-2018')\n",
    "#fig.savefig('./figs/time_between_insp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load violation data\n",
    "\n",
    "**Source:** ICIS-AIR inspections database ([download summary](https://echo.epa.gov/tools/data-downloads/icis-air-download-summary)).\n",
    "\n",
    "**Known problems:** Texas, Louisiana, Nebraska, North Dakota might only have data after Oct 17, 2014. All other states should have data that's complete, back to to ~2003. Source: [known problems](https://echo.epa.gov/resources/echo-data/known-data-problems#alerts). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_path = os.path.join(data_path,'ICIS-AIR_downloads','ICIS-AIR_VIOLATION_HISTORY.csv')\n",
    "violations = load_violations(violations_path,start_date=start_date,end_date=end_date)\n",
    "\n",
    "#a = violations.groupby(violations['VIOL_DATE'].dt.year).count()\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111)\n",
    "#a[['PGM_SYS_ID']].plot(ax=ax)\n",
    "#ax.set_xlabel('Year')\n",
    "#ax.set_ylabel('Number of violations, nationwide')\n",
    "#ax.set_ylim([0,4000])\n",
    "#fig.savefig('./figs/num_violations_by_year.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean violation data\n",
    "Also \"merge\" violation events that were entered within `insp_event_thresh` days of each other--for the same reason as the inspection events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since previous violation\n",
    "violations['time_since_prev'] = time_since_prev(violations,date_col='VIOL_DATE',group_col='PGM_SYS_ID')\n",
    "violations = merge_events(violations,time_since_col='time_since_prev',days_thresh=insp_event_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the links! \n",
    "Mark all \"failed\" inspections as failed. Include the violation Activity ID with the failed inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGM_SYS_ID</th>\n",
       "      <th>ACTIVITY_ID</th>\n",
       "      <th>STATE_EPA_FLAG</th>\n",
       "      <th>ACTIVITY_TYPE_CODE</th>\n",
       "      <th>ACTIVITY_TYPE_DESC</th>\n",
       "      <th>COMP_MONITOR_TYPE_CODE</th>\n",
       "      <th>COMP_MONITOR_TYPE_DESC</th>\n",
       "      <th>ACTUAL_END_DATE</th>\n",
       "      <th>PROGRAM_CODES</th>\n",
       "      <th>time_since_prev</th>\n",
       "      <th>VIOL</th>\n",
       "      <th>VIOL_ACTID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010000000901110001</td>\n",
       "      <td>3601073581</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PFF</td>\n",
       "      <td>PCE Off-Site</td>\n",
       "      <td>2017-01-20 00:00:00</td>\n",
       "      <td>CAANSPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010000000901110001</td>\n",
       "      <td>3601047975</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PFF</td>\n",
       "      <td>PCE Off-Site</td>\n",
       "      <td>2017-03-10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01000000E000000001</td>\n",
       "      <td>3601532874</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-05-30 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01000000E000000003</td>\n",
       "      <td>3601532881</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-04-18 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01000000E000000004</td>\n",
       "      <td>3601545556</td>\n",
       "      <td>E</td>\n",
       "      <td>INS</td>\n",
       "      <td>Inspection/Evaluation</td>\n",
       "      <td>PCE</td>\n",
       "      <td>PCE On-Site</td>\n",
       "      <td>2018-05-01 00:00:00</td>\n",
       "      <td>CAASIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PGM_SYS_ID ACTIVITY_ID STATE_EPA_FLAG ACTIVITY_TYPE_CODE  \\\n",
       "0  010000000901110001  3601073581              E                INS   \n",
       "1  010000000901110001  3601047975              E                INS   \n",
       "2  01000000E000000001  3601532874              E                INS   \n",
       "3  01000000E000000003  3601532881              E                INS   \n",
       "4  01000000E000000004  3601545556              E                INS   \n",
       "\n",
       "      ACTIVITY_TYPE_DESC COMP_MONITOR_TYPE_CODE COMP_MONITOR_TYPE_DESC  \\\n",
       "0  Inspection/Evaluation                    PFF           PCE Off-Site   \n",
       "1  Inspection/Evaluation                    PFF           PCE Off-Site   \n",
       "2  Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "3  Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "4  Inspection/Evaluation                    PCE            PCE On-Site   \n",
       "\n",
       "       ACTUAL_END_DATE PROGRAM_CODES  time_since_prev  VIOL VIOL_ACTID  \n",
       "0  2017-01-20 00:00:00       CAANSPS              NaN     0        nan  \n",
       "1  2017-03-10 00:00:00           NaN             49.0     0        nan  \n",
       "2  2018-05-30 00:00:00        CAASIP              NaN     0        nan  \n",
       "3  2018-04-18 00:00:00        CAASIP              NaN     0        nan  \n",
       "4  2018-05-01 00:00:00        CAASIP              NaN     0        nan  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_insp = link_viol_insp(inspections,violations,past_thresh=0,future_thresh=insp_viol_thresh_days)\n",
    "new_insp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: save the linked inspections/violations to file\n",
    "Linked inspections will have name \"processed_inspections_futurethresh_XX.csv\" where XX is the value of `insp_viol_thresh_days`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_fname = 'processed_inspections_futurethresh_'+str(insp_viol_thresh_days)+'.csv'\n",
    "new_insp.to_csv(os.path.join(data_path,insp_fname))\n",
    "#viol_fname = 'processed_violations.csv'\n",
    "#violations.to_csv(os.path.join(data_path,viol_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_linking_percentage(violations,new_insp):\n",
    "    total_violations = violations['PGM_SYS_ID'].count()\n",
    "    linked_violations = violations['VIOL'].sum()\n",
    "    percent_linked = linked_violations/total_violations*100\n",
    "    message = \"Less than 60% of violations were linked to inspections. Percentage linked = \"+\\\n",
    "                                                                        \"%.1f\" % percent_linked\n",
    "    assert percent_linked>60, message\n",
    "    \n",
    "TEST_linking_percentage(violations,new_insp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify linking strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PGM_SYS_ID            VIOL_DATE ACTIVITY_ID\n",
      "64403  CO0000000803700069  2006-01-19 00:00:00  3400388117\n",
      "46827  CO0000000803700069  2015-08-17 00:00:00  3600482486\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGM_SYS_ID</th>\n",
       "      <th>ACTUAL_END_DATE</th>\n",
       "      <th>VIOL</th>\n",
       "      <th>VIOL_ACTID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91931</th>\n",
       "      <td>CO0000000803700069</td>\n",
       "      <td>2007-06-18 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91932</th>\n",
       "      <td>CO0000000803700069</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91933</th>\n",
       "      <td>CO0000000803700069</td>\n",
       "      <td>2015-05-19 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3600482486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91934</th>\n",
       "      <td>CO0000000803700069</td>\n",
       "      <td>2017-11-13 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PGM_SYS_ID      ACTUAL_END_DATE  VIOL  VIOL_ACTID\n",
       "91931  CO0000000803700069  2007-06-18 00:00:00     0         nan\n",
       "91932  CO0000000803700069  2011-07-21 00:00:00     0         nan\n",
       "91933  CO0000000803700069  2015-05-19 00:00:00     1  3600482486\n",
       "91934  CO0000000803700069  2017-11-13 00:00:00     0         nan"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "pgmid = random.choice(list(viol_dict.keys()))\n",
    "viols = viol_dict.get(pgmid)\n",
    "insp = new_insp[['PGM_SYS_ID','ACTUAL_END_DATE','VIOL','VIOL_ACTID']][new_insp['PGM_SYS_ID']==pgmid]\n",
    "print(viols)\n",
    "insp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional relevant links\n",
    "\n",
    "Relevant links: \n",
    "* [EPA ECHO](https://echo.epa.gov/)\n",
    "* [EPA ECHO data downloads](https://echo.epa.gov/tools/data-downloads#downloads)\n",
    "* [EPA--How we monitor compliance](https://www.epa.gov/compliance/how-we-monitor-compliance)\n",
    "* [EPA--Air enforcement information](https://www.epa.gov/enforcement/air-enforcement#stationary)\n",
    "* [EPA--Coal fired power plant data](https://www.epa.gov/airmarkets/coal-fired-power-plant-data)\n",
    "\n",
    "Additional data sources: \n",
    "* [National emissions inventory](https://www.epa.gov/air-emissions-inventories/2014-national-emissions-inventory-nei-data) (Use 'data/frs_downloads/FRS_PROGRAM_LINKS.csv' to link my dataset with the NEI dataset). Facilities that emit more of a regulated pollutant might be more likely to violate standards? Some normalization factor might be helpful. \n",
    "* [EPA Air Quality Observations](https://aqs.epa.gov/aqsweb/airdata/download_files.html). Might be some relationship between observations of regulated pollutants and probability of violating standards? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
